import openai
import random
import json
import re
from pymongo import MongoClient
from bson import ObjectId
from tqdm import tqdm  # âœ… ì§„í–‰ë¥  í‘œì‹œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬

# âœ… MongoDB ì—°ê²°
client = MongoClient("mongodb+srv://dataEngineering:0000@cluster0.naylo.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0")
db = client["dataEngineering"]
collection = db["Agoda_jeju"]  # ì˜ˆì‹œ: í˜¸í…”

# âœ… OpenAI ì„¤ì •
openai.api_key = "your_api_key"

# âœ… base prompt
base_prompt = """
ë‹¤ìŒì€ ê´€ê´‘ì§€ ë¦¬ë·°ì…ë‹ˆë‹¤. ë¦¬ë·°ì—ì„œ 10ê°œ ë¯¸ë§Œì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë½‘ê³ , ì¹´í…Œê³ ë¦¬ì™€ ê°ì„±(ê¸ì •/ë¶€ì •/ì¤‘ë¦½)ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”. ì™¸êµ­ì–´ì˜ ê²½ìš° í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.
ì¶œë ¥ í˜•ì‹:
[ì¹´í…Œê³ ë¦¬]
í‚¤ì›Œë“œ - ê°ì„±
"""

# âœ… GPT í˜¸ì¶œ í•¨ìˆ˜
def analyze_review_with_gpt(content):
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë¦¬ë·° í‚¤ì›Œë“œ ê°ì„± ë¶„ì„ ë„ìš°ë¯¸"},
                {"role": "user", "content": base_prompt + "\n\n" + content}
            ],
            temperature=0.2
        )
        return response.choices[0].message.content
    except Exception as e:
        print("âŒ GPT ì˜¤ë¥˜:", e)
        return None

# âœ… ì‘ë‹µ íŒŒì‹± í•¨ìˆ˜
def parse_analysis_result(text):
    result = []
    current_category = None
    for line in text.strip().split("\n"):
        if "[" in line and "]" in line:
            current_category = line.strip("[]")
        elif "-" in line and current_category:
            try:
                keyword, sentiment = line.split(" - ")
                result.append({
                    "category": current_category.strip(),
                    "keyword": keyword.strip(),
                    "sentiment": sentiment.strip()
                })
            except:
                continue
    return result

# âœ… STEP 1: ìœ íš¨í•œ ë¦¬ë·°ë§Œ ìˆ˜ì§‘ (20ì ì´ìƒ, ë¯¸ë¶„ì„)
sample_file = "sampled_reviews.json"

try:
    with open(sample_file, "r", encoding="utf-8") as f:
        sampled_reviews = json.load(f)
    print(f"ğŸ“‚ ê¸°ì¡´ ìƒ˜í”Œ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {len(sampled_reviews)}ê°œ")

except FileNotFoundError:
    print("ğŸ“¤ ìƒ˜í”Œ íŒŒì¼ì´ ì—†ì–´ ìƒˆë¡œ ìƒ˜í”Œë§í•©ë‹ˆë‹¤...")
    all_review_targets = []
    for doc in collection.find():
        for idx, review in enumerate(doc.get("reviews", [])):
            content = review.get("content")
            already_done = "keywords_analysis" in review

            if not already_done and isinstance(content, str) and len(content.strip()) >= 20:
                all_review_targets.append({
                    "_id": str(doc["_id"]),
                    "review_index": idx,
                    "content": content.strip()
                })

    total = len(all_review_targets)
    sample_size = int(total * 0.15)
    sampled_reviews = random.sample(all_review_targets, sample_size)

    with open(sample_file, "w", encoding="utf-8") as f:
        json.dump(sampled_reviews, f, ensure_ascii=False, indent=2)
    print(f"âœ… {sample_size}ê°œì˜ ë¦¬ë·°ë¥¼ ìƒ˜í”Œë§í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

# âœ… STEP 2: GPT ë¶„ì„ ë° DB ì €ì¥
for review_info in tqdm(sampled_reviews, desc="ë¦¬ë·° ë¶„ì„ ì§„í–‰ì¤‘"):
    _id = review_info["_id"]
    idx = review_info["review_index"]
    content = review_info["content"]

    # ì´ë¯¸ ë¶„ì„ëœ ê²½ìš° ìŠ¤í‚µ
    doc = collection.find_one({"_id": ObjectId(_id)})
    if doc and "keywords_analysis" in doc["reviews"][idx]:
        continue

    print(f"\nğŸ“ ë¦¬ë·° ë¶„ì„ ì¤‘: {content[:60]}...")

    gpt_output = analyze_review_with_gpt(content)
    if gpt_output:
        parsed_result = parse_analysis_result(gpt_output)

        # ì½˜ì†”ì— ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        print("ğŸ” ë¶„ì„ ê²°ê³¼:")
        for item in parsed_result:
            print(f" - [{item['category']}] {item['keyword']} ({item['sentiment']})")

        # DBì— ì €ì¥
        collection.update_one(
            {"_id": ObjectId(_id)},
            {"$set": {f"reviews.{idx}.keywords_analysis": parsed_result}}
        )
        print(f"âœ… ì €ì¥ ì™„ë£Œ (index {idx})")
