import json
import time

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut
import re

from wsproto.frame_protocol import NULL_MASK

# âœ… ìœ„ë„/ê²½ë„ í•¨ìˆ˜
geolocator = Nominatim(user_agent="location_finder")

def clean_address(address):
    if 'ëŒ€í•œë¯¼êµ­' in address:
        address = address.split('ëŒ€í•œë¯¼êµ­')[0].strip() + ' ëŒ€í•œë¯¼êµ­'
    parts = list(dict.fromkeys(address.split(',')))
    cleaned = ', '.join(p.strip() for p in parts if p.strip())
    return cleaned

def get_lat_lng(address, retries=3):
    cleaned = clean_address(address)
    for i in range(retries):
        try:
            location = geolocator.geocode(cleaned, timeout=5)
            if location:
                return location.latitude, location.longitude
            return None, None
        except (GeocoderTimedOut, GeocoderUnavailable):
            print(f"âš ï¸ ìœ„ì¹˜ ì¡°íšŒ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... ({i + 1}/{retries})")
            time.sleep(1)
    return None, None


# âœ… ë“œë¼ì´ë²„ ì„¤ì •
options = Options()
options.add_argument("--headless")
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
wait = WebDriverWait(driver, 10)

# âœ… í…ŒìŠ¤íŠ¸ìš© í˜¸í…” ë§í¬ ë¶ˆëŸ¬ì˜¤ê¸° (5ê°œë§Œ)
print("â–¶ï¸ JSON í˜¸í…” ë§í¬ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°")
with open("agoda_links_hayeong.json", "r", encoding="utf-8") as f:
    hotel_links = json.load(f)[:5]

result = []

def crawl_sample_hotel(link):
    print(f"\ní˜¸í…” ì¶”ì  ì‹œì‘: {link}")
    driver.get(link)
    time.sleep(3)
    hotel_info = {}
    hotel_info["detail_page_url"] = link

    try:
        hotel_info["hotel_name"] = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'h1[data-selenium="hotel-header-name"]'))).text
    except:
        hotel_info["hotel_name"] = None

    try:
        address = driver.find_element(By.CSS_SELECTOR, '[data-selenium="hotel-address-map"]').text
    except:
        address = None
    hotel_info["address"] = address

    lat, lng = get_lat_lng(address)
    print(f"â–ªï¸ ìœ„ì¹˜: {lat}, {lng}")
    hotel_info["latitude"] = lat
    hotel_info["longitude"] = lng

    try:
        price = driver.find_element(By.CSS_SELECTOR, '[data-element-name="final-price"]').text.replace("\n", "").strip()
    except:
        price = None
    hotel_info["price"] = price

    try:
        rating_candidates = driver.find_elements(By.XPATH, '//p[contains(@class, "Typographystyled__TypographyStyled-sc-j18mtu-0")]')
        for el in rating_candidates:
            text = el.text.strip()
            if re.match(r'^\d+(\.\d+)?$', text):
                hotel_info["avg_rating"] = text
                break
    except:
        hotel_info["avg_rating"] = None

    # âœ… ë¦¬ë·° ìˆ˜ì§‘ (10ê°œë§Œ)
    reviews_list = []
    page = 1
    while True:
        try:
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.Review-comment')))
            reviews = driver.find_elements(By.CSS_SELECTOR, 'div.Review-comment')
            print(f"  - {len(reviews)}ê°œ ë¦¬ë·° í˜ì´ì§€ {page}")
            for review in reviews:
                try:
                    review_data = {
                        "reviewer": "",
                        "rating": "",
                        "title": "",
                        "content": "",
                        "reviewer_country": "",
                        "reviewer_type": "",
                    }
                    try:
                        # reviewëŠ” í•´ë‹¹ ë¦¬ë·° ë¸”ë¡ ìš”ì†Œ
                        spans = review.find_elements(By.XPATH, './/span')
                        review_data["rating"] = None
                        for span in spans:
                            txt = span.text.strip()
                            if review_data["rating"] is None and re.match(r'^\d+(\.\d+)?$', txt):  # ìˆ«ìë§Œ
                                review_data["rating"] = txt
                            if review_data["rating"]:
                                break
                    except:
                        review_data["rating"] = None
                    try:
                        review_data["title"] = review.find_element(By.CSS_SELECTOR, '[data-testid="review-title"]').text
                    except:
                        review_data["title"] = None
                    try:
                        review_data["content"] = review.find_element(By.CSS_SELECTOR, '[data-testid="review-comment"]').text
                    except:
                        review_data["content"] = None
                    try:
                        reviewer_text = review.find_element(By.CSS_SELECTOR, '[data-info-type="reviewer-name"]').text.strip()
                        nickname, country = (reviewer_text.split("(")[0].strip(), reviewer_text.split("(")[1].replace(")", "").strip()) if "(" in reviewer_text else (reviewer_text, "ì •ë³´ ì—†ìŒ")
                        review_data["reviewer"] = nickname
                        review_data["reviewer_country"] = country
                    except:
                        review_data["reviewer"] = None
                        review_data["reviewer_country"] = None
                    try:
                        review_data["reviewer_type"] = review.find_element(By.CSS_SELECTOR, '[data-info-type="group-name"]').text
                    except:
                        review_data["reviewer_type"] = None
                    reviews_list.append(review_data)
                    if len(reviews_list) >= 10:
                        break
                except:
                    continue
            if len(reviews_list) >= 10:
                break
            next_btn = driver.find_elements(By.XPATH, f'//button[@aria-label="ì´ìš©í›„ê¸° í˜ì´ì§€ë¡œ ì´ë™í•˜ê¸° {page + 1}"]')
            if next_btn:
                driver.execute_script("arguments[0].click();", next_btn[0])
                time.sleep(2)
                page += 1
            else:
                break
        except:
            break

    print(f"  âœ”ï¸ ìˆ˜ì§‘ ë¦¬ë·°: {len(reviews_list)}ê°œ")
    hotel_info["review_count"] = len(reviews_list)
    hotel_info["reviews"] = reviews_list
    return hotel_info

# âœ… í˜¸í…”ë³„ ë¦¬ë·° ìˆ˜ì§‘
for url in hotel_links:
    data = crawl_sample_hotel(url)
    result.append(data)

# ì €ì¥
with open("agoda_test_sample_result.json", "w", encoding="utf-8") as f:
    json.dump(result, f, indent=2, ensure_ascii=False)

print("\nğŸš€ ìˆ˜ì§‘ ì™„ë£Œ! ê²°ê³¼ëŠ” agoda_test_sample_result.jsonì— ì €ì¥ë˜ì–´ìˆìŠµë‹ˆë‹¤.")
driver.quit()
