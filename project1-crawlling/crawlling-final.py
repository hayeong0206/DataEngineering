import json
import time
import os
import re
from pymongo import MongoClient
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderUnavailable

# âœ… MongoDB ì—°ê²°
mongo_uri = "mongodb+srv://dataEngineering:0000@cluster0.naylo.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0"
client = MongoClient(mongo_uri)
db = client["dataEngineering"]
collection = db["Agoda_jeju"]

# âœ… ë“œë¼ì´ë²„ ì„¤ì •
options = Options()
#options.add_argument("--headless=new")  # âœ… ìƒˆ ë°©ì‹ì˜ headless ëª¨ë“œ
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--window-size=1920,1080")  # ê°€ìƒ ë¸Œë¼ìš°ì € ì°½ í¬ê¸°
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
wait = WebDriverWait(driver, 10)

# âœ… ê¸°ì¡´ì— ì €ì¥ëœ í˜¸í…” ë§í¬ ë¶ˆëŸ¬ì˜¤ê¸° (ì¤‘ë‹¨ ì§€ì ë¶€í„° ì‹œì‘ ê°€ëŠ¥í•˜ë„ë¡)
visited_links_file = "visited_hotel_links.json"
if os.path.exists(visited_links_file):
    with open(visited_links_file, "r", encoding="utf-8") as f:
        visited_links = set(json.load(f))
else:
    visited_links = set()

# âœ… ì „ì²´ í˜¸í…” ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
all_hotels = []

# âœ… ìœ„ë„/ê²½ë„ í•¨ìˆ˜
geolocator = Nominatim(user_agent="location_finder")

def clean_address(address):
    if not address:
        return None
    if 'ëŒ€í•œë¯¼êµ­' in address:
        address = address.split('ëŒ€í•œë¯¼êµ­')[0].strip() + ' ëŒ€í•œë¯¼êµ­'
    parts = list(dict.fromkeys(address.split(',')))
    return ', '.join(p.strip() for p in parts if p.strip())

def get_lat_lng(address, retries=3):
    if not address:
        return None, None
    cleaned = clean_address(address)
    for i in range(retries):
        try:
            location = geolocator.geocode(cleaned, timeout=5)
            if location:
                return location.latitude, location.longitude
        except (GeocoderTimedOut, GeocoderUnavailable):
            print(f"âš ï¸ ìœ„ì¹˜ ì¡°íšŒ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... ({i + 1}/{retries})")
            time.sleep(1)
    return None, None

# âœ… í˜¸í…” ë§í¬ ë¶ˆëŸ¬ì˜¤ê¸°
with open("agoda_links_hayeong.json", "r", encoding="utf-8") as f:
    hotel_links = json.load(f)

# âœ… í¬ë¡¤ë§ í•¨ìˆ˜ ì •ì˜
def crawl_sample_hotel(link):
    print(f"\ní˜¸í…” ì¶”ì  ì‹œì‘: {link}")
    driver.get(link)
    time.sleep(3)
    hotel_info = {"detail_page_url": link}

    try:
        hotel_name = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'h1[data-selenium="hotel-header-name"]'))).text
    except:
        hotel_name = None

    hotel_info["hotel_name"] = hotel_name
    print(f"ğŸ¨ í˜¸í…” ì´ë¦„: {hotel_name}")

    try:
        address = driver.find_element(By.CSS_SELECTOR, '[data-selenium="hotel-address-map"]').text
    except:
        address = None
    hotel_info["address"] = address

    lat, lng = get_lat_lng(address)
    hotel_info["latitude"] = lat
    hotel_info["longitude"] = lng

    try:
        price = driver.find_element(By.CSS_SELECTOR, '[data-element-name="final-price"]').text.replace("\n", "").strip()
    except:
        price = None

    hotel_info["price"] = price

    print(f"ğŸ’° ê°€ê²©: {hotel_info['price']}")

    try:
        avg_rating_elem = driver.find_element(
            By.XPATH,
            '//div[@data-element-name="review-plate"]//h2//span[1]'
        )
        avg_rating = avg_rating_elem.text.strip()
        if re.match(r'^\d+(\.\d+)?$', avg_rating):
            hotel_info["avg_rating"] = avg_rating
        else:
            hotel_info["avg_rating"] = None
    except:
        hotel_info["avg_rating"] = None

    # âœ… ì‹¤ì œ ë¦¬ë·° ìˆ˜ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì €ì¥
    try:
        review_text = driver.find_element(By.CSS_SELECTOR,
                                          'p.Typographystyled__TypographyStyled-sc-j18mtu-0.Hkrzy.kite-js-Typography').text
        match = re.search(r'(\d+)', review_text)
        review_count_from_text = int(match.group(1)) if match else 0
    except:
        review_count_from_text = 0

    hotel_info["review_count"] = review_count_from_text

    print(f"ğŸ“ ì£¼ì†Œ: {hotel_info['address']}")
    print(f"ğŸ“ ìœ„ì¹˜: {hotel_info['latitude']}, {hotel_info['longitude']}")
    print(f"â­ í‰ì : {hotel_info['avg_rating']}")
    print(f"â­ ë¦¬ë·° ê°œìˆ˜: {hotel_info['review_count']}")

    reviews_list = []
    page = 1
    while True:
        try:
            reviews = driver.find_elements(By.CSS_SELECTOR, 'div.Review-comment')
            if not reviews:
                print("ğŸ“­ ë¦¬ë·° ì—†ìŒ.")
                break

            page_review_count = 0
            for review in reviews:
                review_data = {}
                try:
                    # í‰ì ì€ ì—¬ëŸ¬ êµ¬ì¡°ë¡œ ì˜¬ ìˆ˜ ìˆì–´, span > ì •ê·œì‹ ìˆ«ì í•„í„° ë°©ì‹ ìœ ì§€ + ì¶”ê°€ XPath ê³ ë ¤
                    rating_found = None

                    # 1ì°¨ ì‹œë„: span ì¤‘ ìˆ«ì í…ìŠ¤íŠ¸ ì°¾ê¸°
                    spans = review.find_elements(By.XPATH, './/span')
                    for span in spans:
                        txt = span.text.strip()
                        if re.match(r'^\d+(\.\d+)?$', txt):
                            rating_found = txt
                            break

                    # 2ì°¨ ì‹œë„: í´ë˜ìŠ¤ ê¸°ë°˜
                    if not rating_found:
                        try:
                            rating_found = review.find_element(By.CLASS_NAME, 'Review-comment-leftScore').text.strip()
                        except:
                            pass

                    review_data["rating"] = rating_found if rating_found else None

                except:
                    review_data["rating"] = None

                try:
                    review_data["title"] = review.find_element(By.CSS_SELECTOR, '[data-testid="review-title"]').text
                except:
                    review_data["title"] = None
                try:
                    review_data["content"] = review.find_element(By.CSS_SELECTOR, '[data-testid="review-comment"]').text
                except:
                    review_data["content"] = None
                try:
                    text = review.find_element(By.CSS_SELECTOR, '[data-info-type="reviewer-name"]').text.strip()
                    name, country = (text.split("(")[0].strip(), text.split("(")[1].replace(")", "").strip()) if "(" in text else (text, "ì •ë³´ ì—†ìŒ")
                    review_data["reviewer"] = name
                    review_data["reviewer_country"] = country
                except:
                    review_data["reviewer"] = None
                    review_data["reviewer_country"] = None
                try:
                    review_data["reviewer_type"] = review.find_element(By.CSS_SELECTOR, '[data-info-type="group-name"]').text
                except:
                    review_data["reviewer_type"] = None
                reviews_list.append(review_data)
                if page_review_count == 0:
                    print(
                        f"ğŸ“ ì²« ë¦¬ë·° (p.{page}): {review_data.get('reviewer')} | í‰ì : {review_data.get('rating')} | {review_data.get('title')}")
                page_review_count += 1

            next_btn = driver.find_elements(By.XPATH, f'//button[@aria-label="ì´ìš©í›„ê¸° í˜ì´ì§€ë¡œ ì´ë™í•˜ê¸° {page + 1}"]')
            if next_btn:
                driver.execute_script("arguments[0].scrollIntoView(true);", next_btn[0])
                time.sleep(1)
                driver.execute_script("arguments[0].click();", next_btn[0])
                time.sleep(3)
                page += 1
            else:
                print("â›”ï¸ ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ. ë¦¬ë·° ìˆ˜ì§‘ ì¢…ë£Œ")
                break
        except Exception as e:
            print("â— ë¦¬ë·° ìˆ˜ì§‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ:", e)
            break

    # âœ… ë¦¬ë·° ìµœëŒ€ ê°¯ìˆ˜ ìˆ˜ì§‘ í›„ ì €ì¥
    hotel_info["reviews"] = reviews_list
    all_hotels.append(hotel_info)
    collection.insert_one(hotel_info)
    visited_links.add(link)
    with open(visited_links_file, "w", encoding="utf-8") as f:
        json.dump(list(visited_links), f, ensure_ascii=False, indent=2)
    print(f"âœ… MongoDB ë° visited_links ì €ì¥ ì™„ë£Œ: {hotel_name} (ë¦¬ë·° {len(reviews_list)}ê±´)")

    return hotel_info



# âœ… ìˆ˜ì§‘ ì‹¤í–‰
for url in hotel_links:
    if url in visited_links:
        print(f"â© ì´ë¯¸ ìˆ˜ì§‘ëœ ë§í¬ì…ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤: {url}")
        continue  # ì´ë¯¸ ìˆ˜ì§‘í•œ ë§í¬ëŠ” ê±´ë„ˆëœ€
    data = crawl_sample_hotel(url)

# âœ… ìˆ˜ì§‘ ë°ì´í„° jsonìœ¼ë¡œ ì €ì¥
all_data = list(collection.find({}, {"_id": 0}))
with open("../project1/agoda_hotel_details.json", "w", encoding="utf-8") as f:
    json.dump(all_data, f, ensure_ascii=False, indent=2)

print("\nâœ… ëª¨ë“  ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ")
driver.quit()
